{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5896b1a6-8ed4-4484-96e5-50d0ac10b73a",
   "metadata": {},
   "source": [
    "# [Supervised Fine-tuning Trainer](https://huggingface.co/docs/trl/sft_trainer)\n",
    "\n",
    "Supervised fine-tuning (or SFT for short) is a crucial step in RLHF. In TRL we provide an easy-to-use API to create your SFT models and train them with few lines of code on your dataset.\n",
    "\n",
    "[Python Script](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f636b5-91b3-4a45-a6cf-334425eac4df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install peft==0.7.1\n",
    "# !pip3 install trl==0.7.4\n",
    "# !pip3 install transformer==4.36.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd24274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AIT\\Sem2\\NLP\\NLP_Assignments\\nlp_assignment\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\AIT\\Sem2\\NLP\\NLP_Assignments\\nlp_assignment\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.36.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7263f867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import trl\n",
    "trl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74ed1948-2b9b-4324-ba26-36b6c95fdbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b16f67f1-c0e4-40e9-b192-4d1a9cfbfb17",
   "metadata": {},
   "source": [
    "## Instruction-Tuning\n",
    "Train on completions only\n",
    "- Use the DataCollatorForCompletionOnlyLM to train your model on the generated prompts only.\n",
    "- Note that this works only in the case when packing=False.\n",
    "- To instantiate that collator for instruction data, pass a response template and the tokenizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1ea5ec-482c-4520-bd97-3ccc1f2961f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'instruction', 'output'],\n",
       "    num_rows: 52002\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load the dataset\n",
    "from datasets import load_dataset\n",
    "dataset_train = load_dataset('json', data_files='data/alpaca_data.json', split='train')\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6ee677-ddc8-4a81-9d86-9219de3d84f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '(A musical note)',\n",
       " 'instruction': 'Name the given musical note.',\n",
       " 'output': 'The musical note is an F sharp.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf9b7c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 8.10k/8.10k [00:00<?, ?B/s]\n",
      "Downloading readme: 100%|██████████| 30.0/30.0 [00:00<?, ?B/s]\n",
      "Downloading data: 100%|██████████| 621k/621k [00:00<00:00, 1.16MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\.cache\\huggingface\\datasets\\downloads\\07bde58ae497102ab81d326d84eafcf6c2c7e8df8cd8b8d0ef64d9eceab41ada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating eval split: 805 examples [00:00, 29113.05 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output'],\n",
       "    num_rows: 805\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_eval = load_dataset(\"tatsu-lab/alpaca_eval\", split='eval', trust_remote_code=True)\n",
    "dataset_eval = dataset_eval.remove_columns([\"generator\", \"dataset\"])\n",
    "dataset_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8433703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'what are five important topics for game design',\n",
       " 'output': '1. Storytelling\\n2. Player Mechanics\\n3. Art Direction\\n4. Level Design\\n5. User Interface Design'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_eval[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69100196-d9d8-4791-9e11-6e93f1bd7550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AIT\\Sem2\\NLP\\NLP_Assignments\\nlp_assignment\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\LEGION\\.cache\\huggingface\\hub\\models--distilgpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "d:\\AIT\\Sem2\\NLP\\NLP_Assignments\\nlp_assignment\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "d:\\AIT\\Sem2\\NLP\\NLP_Assignments\\nlp_assignment\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load the model & Tokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name_or_path = \"distilgpt2\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, device_map = 'auto')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Make sure to pass a correct value for max_seq_length as the default value will be set to min(tokenizer.model_max_length, 1024).\n",
    "max_seq_length = min(tokenizer.model_max_length, 1024)\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d301f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['instruction', 'output'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_eval[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cdc0605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': ['', ''],\n",
       " 'instruction': ['Give three tips for staying healthy.',\n",
       "  'What are the three primary colors?'],\n",
       " 'output': ['1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.',\n",
       "  'The three primary colors are red, blue, and yellow.']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75210c9",
   "metadata": {},
   "source": [
    "### Standard-Alpaca : Format your input prompts\n",
    "For instruction fine-tuning, it is quite common to have two columns inside the dataset: one for the prompt & the other for the response.\n",
    "\n",
    "This allows people to format examples like Stanford-Alpaca did as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d350a2-002b-40e2-8c10-9afea5923cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.',\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat are the three primary colors?\\n\\n### Response:\\nThe three primary colors are red, blue, and yellow.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def formatting_prompts_func(examples):\n",
    "\toutput_texts = []\n",
    "\n",
    "\tfor i in range(len(examples['instruction'])):\n",
    "\t\tinstruction = examples[\"instruction\"][i]\n",
    "\t\tinput_text = examples[\"input\"][i] if 'input' in examples.keys() else \"\"\n",
    "\t\tresponse = examples[\"output\"][i]\n",
    "\t\n",
    "\t\tif len(input_text) > 1:\n",
    "\t\t\ttext = f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input_text}\n",
    "\n",
    "### Response:\n",
    "{response}\n",
    "\"\"\".strip()\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\ttext = f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "{response}\n",
    "\"\"\".strip()\n",
    "\n",
    "\t\toutput_texts.append(text)\n",
    "\n",
    "\treturn output_texts\n",
    "\n",
    "#check instruction-prompt\n",
    "formatting_prompts_func(dataset_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4902398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'What are the names of some famous actors that started their careers on Broadway?',\n",
       " 'output': 'Some famous actors that started their careers on Broadway include: \\n1. Hugh Jackman \\n2. Meryl Streep \\n3. Denzel Washington \\n4. Julia Roberts \\n5. Christopher Walken \\n6. Anthony Rapp \\n7. Audra McDonald \\n8. Nathan Lane \\n9. Sarah Jessica Parker \\n10. Lin-Manuel Miranda'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_eval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44cf1dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForCompletionOnlyLM(tokenizer=GPT2TokenizerFast(name_or_path='distilgpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}, mlm=False, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the DataCollatorForCompletionOnlyLM to train your model on the generated prompts only\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "response_template = \"### Response:\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28385087-8eb8-4b83-a7dd-1313bf591b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:01<00:00, 6948.87 examples/s]\n",
      "Map: 100%|██████████| 805/805 [00:00<00:00, 4745.49 examples/s]\n",
      "  0%|          | 0/15000 [00:00<?, ?it/s]d:\\AIT\\Sem2\\NLP\\NLP_Assignments\\nlp_assignment\\Lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "  3%|▎         | 502/15000 [00:43<19:28, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5646, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1002/15000 [01:25<19:38, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5457, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1502/15000 [02:08<19:04, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4884, 'learning_rate': 4.5e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2002/15000 [02:50<17:54, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.46, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2501/15000 [03:38<19:40, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4181, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3001/15000 [04:27<17:29, 11.43it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4617, 'learning_rate': 4e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 3501/15000 [05:13<16:20, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4227, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4001/15000 [05:58<15:57, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3986, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 4501/15000 [06:42<18:30,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3853, 'learning_rate': 3.5e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5000/15000 [07:33<14:29, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4144, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 5000/15000 [07:44<14:29, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.275275945663452, 'eval_runtime': 10.3966, 'eval_samples_per_second': 77.429, 'eval_steps_per_second': 38.763, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AIT\\Sem2\\NLP\\NLP_Assignments\\nlp_assignment\\Lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      " 37%|███▋      | 5500/15000 [08:39<15:51,  9.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0803, 'learning_rate': 3.1666666666666666e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6002/15000 [09:31<17:16,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1074, 'learning_rate': 3e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 6501/15000 [10:22<13:49, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0902, 'learning_rate': 2.8333333333333335e-05, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7000/15000 [11:14<12:55, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0769, 'learning_rate': 2.6666666666666667e-05, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 7502/15000 [12:04<12:34,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.125, 'learning_rate': 2.5e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8002/15000 [12:48<10:02, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0503, 'learning_rate': 2.3333333333333336e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 8502/15000 [13:32<09:24, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0957, 'learning_rate': 2.1666666666666667e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9002/15000 [14:16<08:43, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0874, 'learning_rate': 2e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 9502/15000 [14:58<07:47, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0937, 'learning_rate': 1.8333333333333333e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10000/15000 [15:41<06:48, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0955, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 10000/15000 [15:52<06:48, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2738211154937744, 'eval_runtime': 10.3595, 'eval_samples_per_second': 77.707, 'eval_steps_per_second': 38.902, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10000/15000 [15:52<06:48, 12.25it/s]d:\\AIT\\Sem2\\NLP\\NLP_Assignments\\nlp_assignment\\Lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      " 70%|███████   | 10502/15000 [16:37<06:04, 12.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9015, 'learning_rate': 1.5e-05, 'epoch': 2.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11001/15000 [17:25<05:32, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8978, 'learning_rate': 1.3333333333333333e-05, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 11501/15000 [18:12<05:22, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.883, 'learning_rate': 1.1666666666666668e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12001/15000 [19:01<04:55, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8697, 'learning_rate': 1e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 12501/15000 [19:50<04:15,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9237, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13000/15000 [20:41<03:15, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9256, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 13502/15000 [21:32<02:28, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8845, 'learning_rate': 5e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14002/15000 [22:24<01:41,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8336, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 14502/15000 [23:16<00:51,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8837, 'learning_rate': 1.6666666666666667e-06, 'epoch': 2.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [24:07<00:00, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8783, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 15000/15000 [24:18<00:00, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2890400886535645, 'eval_runtime': 11.6468, 'eval_samples_per_second': 69.118, 'eval_steps_per_second': 34.602, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [24:23<00:00, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1463.4588, 'train_samples_per_second': 20.499, 'train_steps_per_second': 10.25, 'train_loss': 2.1447730875651043, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15000, training_loss=2.1447730875651043, metrics={'train_runtime': 1463.4588, 'train_samples_per_second': 20.499, 'train_steps_per_second': 10.25, 'train_loss': 2.1447730875651043, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './results', #default = 'tmp_trainer'\n",
    "    save_strategy = 'epoch',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    gradient_checkpointing = True,\n",
    "    per_device_train_batch_size = 2,\n",
    "    per_device_eval_batch_size = 2,\n",
    "    num_train_epochs = 3, #default = 3\n",
    ")\n",
    "\n",
    "# Step 3: Define the Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args = training_args,\n",
    "    train_dataset = dataset_train.select(range(10000)),\n",
    "    eval_dataset = dataset_eval,\n",
    "    formatting_func = formatting_prompts_func,\n",
    "    data_collator = collator,\n",
    "    max_seq_length = max_seq_length,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fe24328",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('model/instruction_tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5da45651",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"model/instruction_tuning\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, device_map = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "208c25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9963e503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'What should I eat today? Eat any fruits and vegetables I find popular and healthy? Yes, I eat plenty of fruits and vegetables. No matter how much I eat, I usually take a tablespoon of sugar that’s a part of the fiber they used to achieve their goal. I usually eat a variety of fruits and vegetables, vitamins and minerals, and other essential nutrients like potassium and calcium, phosphorus, and potassium. Plus, I usually eat plenty of fruits and vegetables every day. However, it’s important to keep in mind that getting regular exercise is important, so eating healthy meals throughout your day is something you should never miss! Exercise also helps to build confidence and self-esteem after weight loss. Lastly, it’s important to keep a balanced diet throughout the day. Have a cup of coffee or light snacks when needed! Enjoy! #Baking #Sleep #Vegan #Fruits #Vegan #Fruits #Vegan #Bananas #Bananas #Plump #Wash #MakesItFrog #Vegan #Vegan #Organic #Vegan #Vegan #ReducingGreens #Vegan #Vegetable #Potato #Plump #Healthy #Vegan #Plump #Plump #Pill #Fost #Vegan #Plump #Pest #Vegan #Protein #Vegan #Protein #Vegan #Vegan #Vegan #Protein #Vegan #Vegan #Vegan #Vegan #Plump #Vegan #Vegan #Protein #Vegan #Vegan #Vegan #Vegan #Vegan #Protein #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Protein #Vegan #Vegan #Vegan #Vegan #Protein #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #Vegan #'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator(\"What should I eat today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5b84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
